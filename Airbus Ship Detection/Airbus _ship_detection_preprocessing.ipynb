{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><span style=\"font-size:30px\">Airbus Ship Detection</span></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shipping traffic is growing fast. More ships increase the chances of infractions at sea like environmentally devastating ship accidents, piracy, illegal fishing, drug trafficking, and illegal cargo movement. This has compelled many organizations, from environmental protection agencies to insurance companies and national government authorities, to have a closer watch over the open seas.<br>\n",
    "\n",
    "Airbus offers comprehensive maritime monitoring services by building a meaningful solution for wide coverage, fine details, intensive monitoring, premium reactivity and interpretation response. Combining its proprietary-data with highly-trained analysts, they help to support the maritime industry to increase knowledge, anticipate threats, trigger alerts, and improve efficiency at sea.\n",
    "\n",
    "A lot of work has been done over the last 10 years to automatically extract objects from satellite images with significative results but no effective operational effects. Now Airbus would like to increase the accuracy and speed of automatic ship detection.\n",
    "\n",
    "To achieve this goal Airbus provides a folder 'train_v2' with 192556 aerial coloured photos  where, in some cases, there are several ships.These photos have an identical size of 768 pixels  x 768 pixels.\n",
    "\n",
    "Airbus also provides a csv file where there are annotations of previous ships positions using a special encoding. In the arrays (mathematical represention of the photos), every pixel has been given an index number taking the top left pixel as a beginning (first row and first column of the array).<br> \n",
    "\n",
    "After that initialisation, we are going over all the array, row by row adding one to the index number of the pixels. That means we have index 1 in the top left pixel and 589824 (768x768) and the bottom right pixel.In case that pixel belongs to a ship a value of 1 will be given to the related array value, conversely if the pixel does not belong to a ship a value of 0 will be given to the related array value. \n",
    "\n",
    "The goal of this challenge is to give the best prediction for ships position in new photos. \n",
    "\n",
    "In image cases, deep learning algorithms offer quite good solutions by applying convolutional networks. There are basically 2 kind of networks suitable for this detection:\n",
    "\n",
    ".detection network (SSD,Faster RCN)<br>\n",
    ".segmentation network (Unet,FCN)<br><br>\n",
    "Detection networks are usually exploiting the use of a pretrained networks which have been trained previously by standard images where several varied objects are present. In the case of plane or satellite images, it is more difficult to benefit of those standard images. From a sky view, ships are seen as small blobs and pretrained features are not useful.\n",
    "\n",
    "Segmentation networks may also use pretrained networks, however some of them do not need them. Particularly there is one segmentation network which gives  good results with few image samples. This network is called Unet and is divided in 2 parts, encoder and decoder sub networks.\n",
    "\n",
    "Encoder Sub Network extracts features from images keeping at each stage the main relevant pixels. Decoder Sub Networks reconstructs original images by recovering original context associated with features extracted previously. In Unet in each step of Encoder Nerwork is connected directly to same level step in Decoder Sub Network.\n",
    "\n",
    "The main drawbacks of these neural networks are the need of a quick processor as we have a lot of parameters to calculate as well as big RAM memory to store them temporarily.\n",
    "\n",
    "In my case I have made an first attempt to use my PC with a simple Unet network and a small amount of photos. With my CPU it took about 1 hour to achieve 1 epoch (1 iteration of overall network). With Graphics GPU, it seemed to work faster however I got an out Of Memory error due to 2GB RAM limitation associated to GPU. As memory could not be shared by CPU and GPU in tensorflow, I took the option of Google Collaboratory where I can use GPU with a maximum of 12GB RAM.\n",
    "\n",
    "The main problem of this solution is that there is not enough hardrive Memory in Google Collaboratory to store all the initial images (26GB). So a trade will be achieved and the first part of the processing will be performed in Jupyter Notebook in my own PC and then the images selected for validation and test will be upload to Google Collaboratory.\n",
    "\n",
    "Before applying images to segmentation neural networks, a preclassification network will be introduced to check if the final results can be improved. If the preclassification does not improve our results, it will be discarded and only the segmentation network will remain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:20px\">Data Preprocessing</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before beginning of data preprocessing, 3 folders will be dowloaded from Kaggle platform: __train_v2__,__test_v2__ and __train_ship_segmentations_v2.csv__.\n",
    "\n",
    "- __train_v2__ folder includes all the images that can be applied to our segmentation neural network (26GB) <br>\n",
    "- __test_v2__ folder includes all the images that will be used to generate annotations(2GB)<br>\n",
    "- __train_ship_segmentations_v2.csv__ folder includes a csv file with annotations of all images of __train_v2__ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the python libraries required \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels\n",
       "0  00003e153.jpg                                                NaN\n",
       "1  0001124c7.jpg                                                NaN\n",
       "2  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...\n",
       "3  000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...\n",
       "4  000194a2d.jpg  51834 9 52602 9 53370 9 54138 9 54906 9 55674 ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading annotations: first column is image file name and second column is EncodedPixels \n",
    "#EncodedPixels is a string where ships position is codified in image related mask\n",
    "#In that mask pixels have only 2 values (0 or 1).\n",
    "#A pixel with value of 1 belongs to a ship in the original image, a pixel with value 0 does not \n",
    "#belong to a ship in the original image\n",
    "#run length encoding is made of pairs 'position1 length1 position2 length2 ......positionN lengthN'  \n",
    "#pixels who are in the range [positionI,positionI+lengthI] have value 1\n",
    "masks = pd.read_csv('../Downloads/train_ship_segmentations_v2.csv/train_ship_segmentations_v2.csv')\n",
    "masks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 42556  images with one or more ships\n",
      "There are 150000 images with one or more ships\n"
     ]
    }
   ],
   "source": [
    "#dataframe 'ships' with images with one or more ships\n",
    "ships=masks.copy()\n",
    "ships.dropna(inplace=True)\n",
    "#dataframe 'noships' with images with no ships\n",
    "noships=masks.copy()\n",
    "noships = noships[pd.isnull(noships['EncodedPixels'])]\n",
    "\n",
    "print('There are {}  images with one or more ships'.format(len(ships['ImageId'].unique())))\n",
    "print('There are {} images with one or more ships'.format(len(noships['ImageId'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run length encoding codes each ship in one line of the csv file. So if there are 3 ships in the\n",
    "#image, there will be 3 lines with the same ImageId and different EncodedPixels features\n",
    "\n",
    "#grouping in one line all the EncodedPixels features corresponding to the same ImageId\n",
    "ships['EncodedPixels']= ships['EncodedPixels'].apply(lambda x: x+' ')\n",
    "ships=ships.groupby(['ImageId'],as_index=False).sum()\n",
    "ships['EncodedPixels']= ships['EncodedPixels'].apply(lambda x: x.rstrip())\n",
    "#insertion of a new feature 'ship' which value 1 means there is some ships and value 0 means\n",
    "#there is no ships\n",
    "masks['ship'] = masks['EncodedPixels'].apply(lambda x: 1 if isinstance(x, str) else 0)\n",
    "#if images have one or more ships, 'ship' features will be transform in the number of ships\n",
    "# in that image\n",
    "sum_ships=masks[masks['ship']==1].groupby(['ImageId'],as_index=False).agg({'ship': 'sum'})\n",
    "ships['ship']=sum_ships['ship']\n",
    "ships['ship']=pd.to_numeric(ships['ship'])\n",
    "\n",
    "masks.drop(['ship'],axis=1,inplace=True)\n",
    "#new feature 'size' will be added to show image size in bytes\n",
    "ships['size']=ships['ImageId'].apply(lambda x: os.path.getsize('../Downloads/train_v2/'+x))\n",
    "\n",
    "noships['ship']=0\n",
    "noships['size']=noships['ImageId'].apply(lambda x: os.path.getsize('../Downloads/train_v2/'+x))\n",
    "#dataframe 'allships' groups images with ships and no ships with additional features 'ship'\n",
    "#and size\n",
    "all_ships=pd.concat([ships,noships],axis=0)\n",
    "#after concatenation the position of images with and without ships will be shuffled\n",
    "all_ships = all_ships.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>ship</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3d0f061ab.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>199102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d3590376c.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>93351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f67d52251.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>181992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6a0b1741e.jpg</td>\n",
       "      <td>188305 2 189071 4 189836 8 190602 10 191367 13...</td>\n",
       "      <td>1</td>\n",
       "      <td>129323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bcfd35f61.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>95703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels  ship  \\\n",
       "0  3d0f061ab.jpg                                                NaN     0   \n",
       "1  d3590376c.jpg                                                NaN     0   \n",
       "2  f67d52251.jpg                                                NaN     0   \n",
       "3  6a0b1741e.jpg  188305 2 189071 4 189836 8 190602 10 191367 13...     1   \n",
       "4  bcfd35f61.jpg                                                NaN     0   \n",
       "\n",
       "     size  \n",
       "0  199102  \n",
       "1   93351  \n",
       "2  181992  \n",
       "3  129323  \n",
       "4   95703  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ships.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'size' feature has been added to separate high resolution images from low resolution images. This separation can help to detect possible bad images which could lead to an erroneous ship detection results. If we choose a threshold of 45000 bytes, we can notice that low resolution images are very few (553) and they are mainly images without ships (449) with a background color closed to black. In low resolution images with ships we do not see any corruption so this feature will be discarded without deleting any of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#low resolution images number\n",
    "len(all_ships[all_ships['size']<45000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageId          449\n",
       "EncodedPixels      0\n",
       "ship             449\n",
       "size             449\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#low resolution images without ships\n",
    "low_resolution=all_ships[all_ships['size']<45000]\n",
    "low_resolution[low_resolution['ship']==0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that if we separate the number of images by the number of ships included in each image there is a high unbalanced between images with and without ships. So an undersampling process will be performed mainly concerning images without ships(150000). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     150000\n",
       "1      27104\n",
       "2       7674\n",
       "3       2954\n",
       "4       1622\n",
       "5        925\n",
       "6        657\n",
       "7        406\n",
       "8        318\n",
       "9        243\n",
       "10       168\n",
       "11       144\n",
       "12       124\n",
       "14        76\n",
       "13        75\n",
       "15        66\n",
       "Name: ship, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ships['ship'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to discard a big amount of photos because in Google Collaboratory, even with a 12GB maximum memory, memory limit can be reach very fastly when complex neural networks are trained. So,about a maximum of 4000 images will be chosen to be uploaded to Google Collaboratory. If the number of ships in each image is considered as the value of a class, a maximum number of images per class will be selected. In this case there are 15 classes and as beyond class '7' all the classes have less than 400 images, a maximim 400 images per class will be decided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the downsampling will be performed by sample function. 400 images maximum will be chosen by class\n",
    "# in practice only images number with 7 ships or less ships will be reduced\n",
    "MAX_IMAGES_PER_CLASS=400\n",
    "\n",
    "sample_balanced=all_ships.groupby('ship').apply(lambda x: x.sample(MAX_IMAGES_PER_CLASS) if len(x)>MAX_IMAGES_PER_CLASS else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     400\n",
       "1     400\n",
       "2     400\n",
       "3     400\n",
       "4     400\n",
       "5     400\n",
       "6     400\n",
       "7     400\n",
       "8     318\n",
       "9     243\n",
       "10    168\n",
       "11    144\n",
       "12    124\n",
       "13     75\n",
       "14     76\n",
       "15     66\n",
       "Name: ship, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample_balanced is the dataframe that will be chosen to upload images to Google Collaboratory\n",
    "sample_balanced['ship'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageId          4414\n",
       "EncodedPixels    4014\n",
       "ship             4414\n",
       "size             4414\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_balanced.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>ship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e2e6c2dc5.jpg</td>\n",
       "      <td>246392 1 247159 3 247926 5 248693 7 249460 9 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51f397469.jpg</td>\n",
       "      <td>381587 1 382353 4 383120 5 383887 7 384654 9 3...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46507a0d0.jpg</td>\n",
       "      <td>32295 11 33063 30 33831 38 34598 42 35366 42 3...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a44b42d54.jpg</td>\n",
       "      <td>499801 1 500568 3 501335 5 502102 7 502869 9 5...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>444e9617e.jpg</td>\n",
       "      <td>302422 2 303188 4 303954 7 304721 8 305489 9 3...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels  ship\n",
       "0  e2e6c2dc5.jpg  246392 1 247159 3 247926 5 248693 7 249460 9 2...     1\n",
       "1  51f397469.jpg  381587 1 382353 4 383120 5 383887 7 384654 9 3...     7\n",
       "2  46507a0d0.jpg  32295 11 33063 30 33831 38 34598 42 35366 42 3...    14\n",
       "3  a44b42d54.jpg  499801 1 500568 3 501335 5 502102 7 502869 9 5...     8\n",
       "4  444e9617e.jpg  302422 2 303188 4 303954 7 304721 8 305489 9 3...     3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'size' feature is eliminated \n",
    "sample_balanced.drop(['size'],axis=1,inplace=True)\n",
    "#rows in this dataframe are shuffled\n",
    "sample_balanced = sample_balanced.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "sample_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sample_balanced dataframe we are going to copy corresponding images\n",
    "# into airbus_ship_images_4414 folder which will be used in Google Collaboratory \n",
    "for index,row in sample_balanced.iterrows():\n",
    "    newPath = shutil.copy('../Downloads/train_v2/'+row['ImageId'],'../Downloads/airbus_ship_images_4414/')\n",
    "#sample_balanced dataframe with previous images annotations will be copied into a csv file \n",
    "#to be uploaded to Google Collaboratory \n",
    "sample_balanced.to_csv('ships_dataset.csv', sep=',', encoding='utf-8',index=False)\n",
    "shutil.copy('ships_dataset.csv','../Downloads/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The criterium for choosing these previous images was the maximum balance between classes. With this criterium, we can expect better results in segmentation neural networks.\n",
    "\n",
    "Now, as I said at the beginning, we foresee to check if an images preclassification can improve segmentation results. For this preclassification, a balance of images with and without ships is required for good features extraction. \n",
    "\n",
    "As in the previous case, due to Google Collaboratory RAM size in neural networks training, a maximum of about 4000 images will be chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>ship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50eddd13d.jpg</td>\n",
       "      <td>257763 3 258531 7 259299 10 260066 11 260834 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71d47dcfb.jpg</td>\n",
       "      <td>224343 3 225105 9 225867 16 226632 16 227400 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f3b41e1f7.jpg</td>\n",
       "      <td>320239 6 321002 11 321770 11 322538 11 323306 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6a7de5958.jpg</td>\n",
       "      <td>521862 2 522630 6 523397 10 524165 14 524933 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accdf6c3e.jpg</td>\n",
       "      <td>63052 1 63820 2 64588 4 65357 4 66125 5 66894 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels  ship\n",
       "0  50eddd13d.jpg  257763 3 258531 7 259299 10 260066 11 260834 1...     1\n",
       "1  71d47dcfb.jpg  224343 3 225105 9 225867 16 226632 16 227400 1...     1\n",
       "2  f3b41e1f7.jpg  320239 6 321002 11 321770 11 322538 11 323306 ...     1\n",
       "3  6a7de5958.jpg  521862 2 522630 6 523397 10 524165 14 524933 1...     1\n",
       "4  accdf6c3e.jpg  63052 1 63820 2 64588 4 65357 4 66125 5 66894 ...     1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in this case we will select maximum 155 images with ships per class and 2035 images without ships\n",
    "#the undersampling will be performed by sample function\n",
    "MAX_IMAGES_SHIP_CLASS=155\n",
    "MAX_IMAGES_NONSHIP_CLASS=2035\n",
    "sample_ship=all_ships[all_ships['ship']!=0].groupby('ship').apply(lambda x: x.sample(MAX_IMAGES_SHIP_CLASS) if len(x)>MAX_IMAGES_SHIP_CLASS else x)\n",
    "sample_nonship=all_ships[all_ships['ship']==0].groupby('ship').apply(lambda x: x.sample(MAX_IMAGES_NONSHIP_CLASS))\n",
    "sample_class=pd.concat([sample_ship,sample_nonship],axis=0,ignore_index=True)\n",
    "sample_class = sample_class.sample(frac=1).reset_index(drop=True)\n",
    "sample_class.drop(['size'],axis=1,inplace=True)\n",
    "sample_class['ship']=sample_class['ship'].apply(lambda x: 1 if x!=0 else x)\n",
    "sample_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images with    ships  2035\n",
      "Images without ships  2035\n"
     ]
    }
   ],
   "source": [
    "print(\"Images with    ships \",len(sample_class[sample_class['ship']==1]))\n",
    "print(\"Images without ships \",len(sample_class[sample_class['ship']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sample_class dataframe we are going to copy corresponding images\n",
    "# into airbus_ship_images_4070 folder which will be used in Google Collaboratory \n",
    "for index,row in sample_class.iterrows():\n",
    "    newPath = shutil.copy('../Downloads/train_v2/'+row['ImageId'],'../Downloads/airbus_ship_images_4070/')\n",
    "#sample_class dataframe with previous images annotations will be copied into a csv file \n",
    "#to be uploaded to Google Collaboratory\n",
    "sample_class.to_csv('new_ships_dataset.csv', sep=',', encoding='utf-8',index=False)\n",
    "shutil.copy('new_ships_dataset.csv','../Downloads/')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
